{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d217864-9252-41dd-928d-4acb40ced926",
   "metadata": {},
   "source": [
    "# üß™ Workshop 2: Objective Design and Local Dynamics\n",
    "\n",
    "> This notebook is provided in a clean, non-executed version for the reader to try out on the problem.\n",
    ">\n",
    "> A model answer and executive summary can be found in the *worked* version.\n",
    "\n",
    "This workshop builds directly on Workshop 1 and marks the transition from gradient interpretation to explicit optimisation dynamics, opening Part 2 of the series.\n",
    "\n",
    "Where Workshop 1 focused on what gradients are and how they are structured, this workshop focuses on what gradients do when they are applied repeatedly. Gradients are no longer treated as static sensitivity maps, but as drivers of parameter evolution.\n",
    "\n",
    "The central shift in perspective is:\n",
    "- from *‚Äúwhat does this gradient look like?‚Äù*\n",
    "- to *‚Äúwhat happens when I follow it?‚Äù*\n",
    "\n",
    "---\n",
    "\n",
    "**Conceptual emphasis**\n",
    "\n",
    "The workshop develops intuition for:\n",
    "- how a single gradient descent step turns sensitivity into motion,\n",
    "- how repeated local updates accumulate into global behaviour,\n",
    "- how objective structure influences optimisation trajectories,\n",
    "- and how gradient geometry affects stability, speed, and convergence.\n",
    "\n",
    "Rather than introducing full training pipelines, the focus remains on controlled, interpretable systems where optimisation dynamics can be reasoned about directly.\n",
    "\n",
    "--- \n",
    "\n",
    "**Key ideas explored include**:\n",
    "- gradient descent as repeated application of vector‚ÄìJacobian products,\n",
    "- implicit objective functions defined by upstream weighting,\n",
    "- the relationship between gradient magnitude, direction, and parameter motion,\n",
    "- conditioning and anisotropy in gradient-driven updates,\n",
    "- how symmetry, nonlinearity, and curvature shape optimisation paths,\n",
    "- and visualising optimisation as movement through parameter space.\n",
    "\n",
    "--- \n",
    "\n",
    "**How this workshop fits in the series**\n",
    "\n",
    "This workshop serves as the conceptual bridge between:\n",
    "- gradient flow and sensitivity analysis (Workshop 1),\n",
    "- and more advanced optimisation topics such as learning rates, curvature, and second-order effects (later in Part 2).\n",
    "\n",
    "By the end of this workshop, gradient descent is no longer a formula, but a geometric process whose behaviour can be anticipated from gradient structure alone.\n",
    "\n",
    "---\n",
    "\n",
    "**What this workshop deliberately does not cover**\n",
    "- Neural network modules (nn.Module)\n",
    "- Optimisers such as Adam, RMSProp, etc.\n",
    "- Datasets, batching, or training loops\n",
    "\n",
    "Those elements are introduced only after optimisation dynamics are conceptually understood.\n",
    "\n",
    "---\n",
    "\n",
    "**Recommended prerequisites**\n",
    "- Completion of Tutorials 1‚Äì4\n",
    "- Workshop 1: From Gradient Flow to Optimisation Intuition\n",
    "- Comfort with gradients, Jacobians, and basic optimisation ideas\n",
    "- Familiarity with linear algebra and nonlinear mappings\n",
    "\n",
    "---\n",
    "\n",
    "**Author: Angze Li**\n",
    "\n",
    "**Last updated: 2026-02-19**\n",
    "\n",
    "**Version: v1.0**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb363e6-7af8-40b7-a60b-58e6866654ff",
   "metadata": {},
   "source": [
    "## üß© Problem: Designing an Objective via Upstream Gradients\n",
    "\n",
    "> Optimisation is not only about how to minimise a loss\n",
    "> ‚Äî it is also about what objective you choose.\n",
    "\n",
    "In this problem, you will implicitly define an objective by choosing an upstream gradient.\n",
    "\n",
    "Consider:\n",
    "```python\n",
    "X = torch.randn(5, 3, requires_grad=True)\n",
    "\n",
    "Y = torch.tanh(X @ X.T)\n",
    "```\n",
    "Here:\n",
    "- `Y` is a **5√ó5 tensor** measuring pairwise interactions,\n",
    "- the output is *symmetric and non-scalar*.\n",
    "\n",
    "---\n",
    "\n",
    "### Task\n",
    "1. Construct an upstream gradient matrix V such that:\n",
    "    - diagonal entries of Y are emphasised,\n",
    "    - off-diagonal entries are penalised.\n",
    "2. Call:\n",
    "```python\n",
    "Y.backward(V)\n",
    "```\n",
    "3. Inspect `X.grad`.\n",
    "\n",
    "---\n",
    "\n",
    "### Questions to think about\n",
    "- What implicit scalar objective are you optimising?\n",
    "- How does changing the diagonal/off-diagonal weighting affect `X.grad`?\n",
    "- Which entries of `X` are encouraged to grow or shrink?\n",
    "- Can you interpret this as encouraging **self-similarity** over **cross-similarity**?\n",
    "\n",
    "---\n",
    "\n",
    "### Hint\n",
    "\n",
    "> You are not optimising `Y` directly.\n",
    "> You are optimising a **weighted trace-like** functional of `Y`.\n",
    "\n",
    "---\n",
    "\n",
    "### Why this problem matters (Bridge to Part 2)\n",
    "\n",
    "This problem quietly introduces:\n",
    "- custom objective design,\n",
    "- structure-aware optimisation,\n",
    "- gradients as *design tools*, not just training signals.\n",
    "\n",
    "Without using:\n",
    "- optimisers,\n",
    "- learning rates,\n",
    "- training loops,\n",
    "\n",
    "you have already answered:\n",
    "\n",
    ">‚ÄúIf I *were* to optimise this system, what direction would the parameters move?‚Äù\n",
    "\n",
    "That is exactly the mindset needed for Part 2."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e30cbac-51bc-461a-aab1-f8cb64a580b8",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed658b1-8620-4c9d-a1da-249e708d2767",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "dc836f2c-593b-4a84-92c2-e0e86cb782fa",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## üîó Trailer: From Gradient Structure to a Single Update Step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c977184c-fa1a-4ac5-863f-6e42e24ced89",
   "metadata": {},
   "source": [
    "So far in Part 1, we have treated gradients as objects to inspect rather than tools to use.\n",
    "We decomposed them, visualised them, and asked where sensitivity lives inside a tensor.\n",
    "\n",
    "Now we briefly connect that structure to motion."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c5b31d0-c4f0-4aa5-9118-13ceb30082ce",
   "metadata": {},
   "source": [
    "### What is gradient descent?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee9c212-4b09-461c-a50c-74d861f8a721",
   "metadata": {},
   "source": [
    "At its simplest, gradient descent is a rule for updating parameters in order to reduce a scalar objective.\n",
    "\n",
    "Given a scalar function\n",
    "$$L(X),$$\n",
    "a single gradient descent step with step size $\\eta > 0$ is:\n",
    "$$X_{\\text{new}} = X - \\eta \\,\\nabla_X L.$$\n",
    "\n",
    "That‚Äôs it.\n",
    "\n",
    "There is no optimiser, no momentum, no learning rate schedule ‚Äî just:\n",
    "- a gradient (direction),\n",
    "- and a step size (scale)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "304a0fbf-427e-49d0-8d1e-c52dcffb4b0f",
   "metadata": {},
   "source": [
    "### What is the ‚Äúloss‚Äù in our case?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88404293-b767-4cd5-afbc-cd9b22e49477",
   "metadata": {},
   "source": [
    "In this notebook, we did not define a conventional loss function.\n",
    "\n",
    "Instead, we implicitly defined a scalar objective via an upstream gradient:\n",
    "$$L(X) = v^\\top \\cdot Y,\n",
    "\\quad \\text{where } Y = \\tanh(X X^\\top).$$\n",
    "\n",
    "The gradient we computed and visualised throughout this workshop is therefore:\n",
    "$$\\nabla_X (v^\\top \\cdot Y).$$\n",
    "\n",
    "Every heatmap you plotted is a **map of how a single gradient descent step would move `X`.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d2dddc-518a-43b9-a663-e5263282d9ea",
   "metadata": {},
   "source": [
    "### One explicit update step"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31889e5-6be0-420d-b51f-301239d6a29c",
   "metadata": {},
   "source": [
    "Using the averaged gradient you computed, a single update would be:\n",
    "$$X_{\\text{new}} = X - \\eta \\,\\nabla_X (v^\\top \\cdot Y).$$\n",
    "\n",
    "What does this mean in practice?\n",
    "- Each entry of `X` moves in the direction indicated by the heatmap.\n",
    "- Regions with larger magnitude move **more strongly**.\n",
    "- Positive and negative regions correspond to opposing update directions, not just strength.\n",
    "- The update respects:\n",
    "    - the symmetry of $X X^\\top$,\n",
    "    - the structure imposed by the upstream weighting `v`,\n",
    "    - and the nonlinear gating of tanh.\n",
    "\n",
    "Nothing ‚Äúnew‚Äù happens here.\n",
    "\n",
    "Optimisation is simply **repeated application of the sensitivity patterns** you have already analysed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a016e1b9-57ce-428f-b6e1-73929911d378",
   "metadata": {},
   "source": [
    "### Why this closes Part 1 (and previews Part 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "904ed912-b450-40d4-935b-c13a9f6b1713",
   "metadata": {},
   "source": [
    "In Part 1, gradients were treated as:\n",
    "- quantities to compute,\n",
    "- structures to interpret,\n",
    "- and signals to decompose.\n",
    "\n",
    "This final step shows that:\n",
    "- **every optimisation algorithm is just a rule for turning gradients into motion**,\n",
    "- the heatmaps you plotted literally encode *where parameters will move next*,\n",
    "- upstream objectives shape optimisation *before* any optimiser is introduced.\n",
    "\n",
    "In **Part 2**, we will:\n",
    "- repeat this step many times,\n",
    "- vary step size $\\eta$,\n",
    "- introduce conditioning, curvature, and geometry,\n",
    "- and study how these local updates accumulate into global behaviour.\n",
    "\n",
    "Conceptually, nothing new is added ‚Äî only repetition.\n",
    "\n",
    "That repetition is optimisation."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
