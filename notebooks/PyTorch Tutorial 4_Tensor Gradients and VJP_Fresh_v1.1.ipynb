{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4f8e9b0-5c07-4952-b9da-dd8e2f74699a",
   "metadata": {},
   "source": [
    "# Scope of this notebook\n",
    "\n",
    "This notebook builds on earlier tutorials and focuses on understanding how PyTorch handles **gradients when the output of a computation is a tensor rather than a scalar.**\n",
    "\n",
    "In particular, it introduces **vector‚ÄìJacobian products** (VJPs) as the fundamental object computed by `autograd` when calling `backward()` on **non-scalar outputs**, and shows how upstream gradients control the flow of sensitivity through the computation graph.\n",
    "\n",
    "The emphasis is on developing conceptual intuition for:\n",
    "- how gradients are defined for tensor-valued outputs,\n",
    "- how explicit upstream gradients interact with the computation graph,\n",
    "- how gradients propagate back to leaf tensors,\n",
    "- and how PyTorch accumulates and manages gradients across backward passes.\n",
    "\n",
    "Key topics covered include:\n",
    "- the distinction between scalar losses and tensor-valued outputs,\n",
    "- how PyTorch computes vector‚ÄìJacobian products via `backward(v)`,\n",
    "- the role of upstream gradients in shaping `inp.grad`,\n",
    "- gradient accumulation and the need to explicitly zero gradients,\n",
    "- and practical interpretation of gradient structure through visualisation.\n",
    "\n",
    "This notebook is intended as a conceptual bridge between:\n",
    "- basic autograd usage with scalar losses (Tutorial 2),\n",
    "- and more advanced topics such as full Jacobians, Jacobian‚Äìvector products, and sensitivity analysis (Tutorial 5 and beyond).\n",
    "\n",
    "It does not cover neural network modules, optimisers, or training pipelines. The focus is strictly on autograd mechanics and gradient interpretation, independent of model architecture.\n",
    "\n",
    "Recommended prerequisites:\n",
    "- Familiarity with PyTorch tensors and basic operations\n",
    "- Understanding of scalar backpropagation and `.backward()`\n",
    "- Basic comfort with gradients and partial derivatives\n",
    "\n",
    "---\n",
    "\n",
    "**Author: Angze Li**\n",
    "\n",
    "**Last updated: 2026-02-06**\n",
    "\n",
    "**Version: v1.1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7867e6a6-d0d5-42da-ac1e-5cb9488ba629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28fc4c4-7925-4ce2-a027-fcf793502f52",
   "metadata": {},
   "source": [
    "### From scalar losses to tensor-valued outputs\n",
    "\n",
    "In most machine learning workflows, we work with a scalar loss function and compute gradients with respect to model parameters.\n",
    "This scalar setting allows PyTorch to apply backpropagation automatically, storing gradients directly in `.grad`.\n",
    "\n",
    "However, not all computations naturally end in a scalar.\n",
    "\n",
    "In many practical and analytical settings, the output of interest is an arbitrary **tensor** rather than a single number. In such cases, a full gradient is no longer *well-defined* in the usual sense. Instead, the derivative of a tensor-valued function is a **Jacobian matrix**, which can be large and expensive to construct explicitly.\n",
    "\n",
    "Rather than forming this Jacobian, PyTorch computes Jacobian products efficiently.\n",
    "\n",
    "Specifically, PyTorch evaluates **vector‚ÄìJacobian products** (VJPs), which answer the question:\n",
    "\n",
    "> How does a weighted combination of the output change with respect to earlier tensors?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b3581-abd5-4139-8066-c7f9b10d50b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "out = (inp+1).pow(2).t()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"leaf tensor inp\\n{inp}\")\n",
    "print(f\"out\\n{out}\")\n",
    "print(f\"First call\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12e46e5-ed45-49ec-ba1e-7597fb2a500b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>What does the code mean?</strong></summary>\n",
    "    \n",
    "#### First Line\n",
    "\n",
    "```python\n",
    "torch.eye()\n",
    "```\n",
    "creates a identity-like matrix (ones on the diagonal, zeros elsewhere). \n",
    "\n",
    "By passing `requires_grad=True`, we tell PyTorch to track all subsequent operations on this tensor so that gradients can be computed during backpropagation.\n",
    "\n",
    "---\n",
    "\n",
    "#### Second Line\n",
    "\n",
    "The variable `out` is now a **tensor-valued output**, not a scalar:\n",
    "```python\n",
    "out = (inp+1).pow(2).t()\n",
    "```\n",
    "This line performs several operations in sequence:\n",
    "1. `inp + 1` adds 1 element-wise to the input tensor.\n",
    "2. `.pow(2)` squares each element, introducing a nonlinear operation (common in machine learning models).\n",
    "3. `.t()` transposes the matrix, changing its shape.\n",
    "\n",
    "As a result, out is a matrix, not a single number.\n",
    "\n",
    "---\n",
    "\n",
    "#### Third Line: why does `backward()` need an argument here?\n",
    "\n",
    "In earlier tutorials, we always called backward() on a scalar loss. In that case, PyTorch *implicitly* assumes an upstream gradient of 1.\n",
    "\n",
    "Here, however, out is not a scalar. Calling:\n",
    "```python\n",
    "out.backward()\n",
    "```\n",
    "would raise an error, because PyTorch does not know which **combination of gradients** you want.\n",
    "\n",
    "Instead, we must explicitly provide an upstream gradient with the **same shape** as `out`:\n",
    "```python\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "```\n",
    "This tells PyTorch:\n",
    "> ‚ÄúCompute the vector‚ÄìJacobian product where the upstream gradient is a tensor of ones.‚Äù\n",
    "\n",
    "---\n",
    "\n",
    "#### Final line: What is `inp.grad` showing us?\n",
    "After calling:\n",
    "```python\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "```\n",
    "PyTorch computes gradients **with respect to all leaf tensors** that have `requires_grad=True`.\n",
    "In this example, the only such tensor is:\n",
    "```python\n",
    "inp\n",
    "```\n",
    "As a result, PyTorch stores the gradient of the output `out` with respect to `inp` in:\n",
    "```python\n",
    "inp.grad\n",
    "```\n",
    "\n",
    "#### Wait a second...\n",
    "This could be counter-intuitive for beginners, as the `backward()` is called on `out`, but the gradient is stored on `inp`. \n",
    "\n",
    "However, the key mental shift is:\n",
    "> `backward()` is not asking ‚Äúwhat is the gradient of this tensor?‚Äù\n",
    ">\n",
    "> It is asking ‚Äúhow did this output depend on earlier tensors?‚Äù\n",
    "\n",
    "In PyTorch, when you call:\n",
    "```python\n",
    "out.backward(torch.ones_like(out))\n",
    "```\n",
    "you are telling PyTorch:\n",
    "> ‚ÄúAssume out represents the end of a computation.\n",
    "> \n",
    ">Please compute how changes in earlier tensors would affect it.‚Äù\n",
    "\n",
    "More precisely, PyTorch computes:\n",
    "$$\\frac{\\partial}{\\partial (\\text{leaf tensors})}\n",
    "\\Big(v_{\\text{upstream}}^{\\top}\\cdot\\text{out}\\Big)$$\n",
    "where:\n",
    "- $v_{\\text{upstream}}$ is the upstream gradient supplied to `backward()` (in our case, `torch.ones_like(out)`, which corresponds to summing all entries of out with **equal weight**; other choices are also valid).\n",
    "- The expression $v_{\\text{upstream}}^{\\top}\\cdot\\text{out}$ is equivalent to $\\sum_i v_{\\text{upstream},i}\\,\\text{out}_i$, giving a scalar as the result. This is called **gradient produced via a vector‚ÄìJacobian product (VJP)**.\n",
    "- Only the leaf tensors (see definition in Tutorial 2) accumulate gradients in their `.grad` attribute during backpropagation (in our case, `inp` is the (only) leaf tensor, and hence PyTorch stores the result of the above derivative in `inp.grad`).\n",
    "\n",
    "Note that mathematically, the gradient (partial derivatives) of a scalar $L$ with respect to a matrix $X \\in \\mathbb{R}^{m\\times n}$ is defined as:\n",
    "$$\\frac{\\partial L}{\\partial X}\n",
    "\\;=\\;\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial L}{\\partial X_{11}} & \\cdots & \\frac{\\partial L}{\\partial X_{1n}} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial L}{\\partial X_{m1}} & \\cdots & \\frac{\\partial L}{\\partial X_{mn}}\n",
    "\\end{bmatrix}$$\n",
    "\n",
    "There are (at least) two reasons why PyTorch does not store the gradient in `out`:\n",
    "1. **`out` is not a parameter.** We don‚Äôt usually update out; we update inputs like weights.\n",
    "2. **Gradients are defined with respect to inputs.** The whole purpose of backpropagation is to answer: ‚ÄúWhich earlier values should I change to reduce the output?‚Äù\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "#### Important clarification\n",
    "\n",
    "The need to pass an argument to `backward()` here is not because we want to call `backward()` multiple times. It is because `out` is non-scalar.\n",
    "\n",
    "The reason we pass `retain_graph=True` is separate:\n",
    "- it allows the same computation graph to be reused in later cells,\n",
    "- which is useful for demonstration and debugging.\n",
    "\n",
    "We will discuss gradient accumulation and zeroing gradients in the next cells.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b64e1-7d08-460e-9ca7-61e939872982",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nSecond call\\n{inp.grad}\")\n",
    "\n",
    "if inp.grad is not None:\n",
    "    inp.grad.zero_()\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "print(f\"\\nCall after zeroing gradients\\n{inp.grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896986bb-4965-4420-8791-5d63cddcf965",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary><strong>Gradient accumulation and zeroing gradients</strong></summary>\n",
    "\n",
    "#### What is happening here?\n",
    "PyTorch accumulates gradients by default.\n",
    "This means that every call to `backward()` adds new gradient contributions to the existing values stored in `.grad`.\n",
    "\n",
    "When we call `backward()` for a second time:\n",
    "```python\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "```\n",
    "without clearing gradients:\n",
    "- PyTorch computes the same gradient again\n",
    "- the newly computed gradient is **added to the existing contents** of `inp.grad`\n",
    "\n",
    "As a result, `inp.grad` after the second call contains the **sum of gradients** from both backward passes, not just the most recent one (we can find that the result of second call is exactly twice as the first call above).\n",
    "\n",
    "This behaviour is intentional and is essential for many training workflows (e.g. gradient accumulation over multiple mini-batches).\n",
    "\n",
    "However, when we intend to reset the gradients, we can use:\n",
    "```python\n",
    "inp.grad.zero_()\n",
    "```\n",
    "This clears the accumulated gradient and sets all entries of `inp.grad` to zero. Now, when we call\n",
    "```python\n",
    "out.backward(torch.ones_like(out), retain_graph=True)\n",
    "```\n",
    "again:\n",
    "- PyTorch computes the gradient from scratch\n",
    "- the result stored in `inp.grad` now reflects only this single backward pass.\n",
    "\n",
    "Now the result is the same as the first call.\n",
    "\n",
    "---\n",
    "\n",
    "#### Why does PyTorch accumulate gradients?\n",
    "PyTorch‚Äôs design assumes that:\n",
    "- users may want to accumulate gradients across multiple forward‚Äìbackward passes,\n",
    "- or combine gradients from multiple loss terms.\n",
    "\n",
    "Because of this, gradient clearing is an **explicit** user responsibility.\n",
    "\n",
    "This is why, in typical training loops, you will often see:\n",
    "```python\n",
    "optimizer.zero_grad()\n",
    "```\n",
    "or \n",
    "```python\n",
    "tensor.grad.zero_()\n",
    "```\n",
    "before each backward pass.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc734004-89ba-489b-9e64-e061f1ed25a7",
   "metadata": {},
   "source": [
    "### üîç Practical exercise: weighted sensitivity of a tensor output\n",
    ">In many real problems, a model does not produce a single scalar output.\n",
    ">Instead, we often care about how sensitive different parts of the output are to changes in the input, possibly with different importance weights.\n",
    "\n",
    "Consider the following setup:\n",
    "```python\n",
    "inp = torch.eye(4, 5, requires_grad=True)\n",
    "out = (inp + 10).pow(3).t()\n",
    "```\n",
    "This produces a tensor-valued output.\n",
    "Suppose now that we care more about *some entries* of `out` than others.\n",
    "\n",
    "---\n",
    "#### üîß Task\n",
    "\n",
    "1. Construct an upstream gradient tensor v with the same shape as out that:\n",
    "    - assigns higher weight to the first row of out,\n",
    "    - and lower (or zero) weight elsewhere.\n",
    "2.\tCall:\n",
    "```python\n",
    "out.backward(v)\n",
    "```\n",
    "3.\tInspect `inp.grad`.\n",
    "\n",
    "---\n",
    "\n",
    "#### üß† Questions to think about\n",
    "- How does changing `v` change `inp.grad`?\n",
    "- Which entries of `inp` are most sensitive to the weighted output?\n",
    "- What does `inp.grad` represent conceptually in this case?\n",
    "\n",
    "---\n",
    "\n",
    "#### üí° Hint (optional)\n",
    "\n",
    ">You are not computing ‚Äúthe gradient of out‚Äù.\n",
    ">\n",
    ">You are computing how a weighted combination of outputs depends on the input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b07b06ad-3389-4154-a896-f5c9335b54fc",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
