{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a66921-db11-4319-aae5-f8a18a00c58d",
   "metadata": {},
   "source": [
    "# Scope of this notebook\n",
    "\n",
    "This notebook introduces core PyTorch **tensor fundamentals**, including tensor creation from Python and NumPy objects, tensor shapes and dimensionality, data types (`dtype`), device placement, arithmetic operations, and in-place operations.\n",
    "\n",
    "The focus is on building **correct intuition** for how tensors behave in PyTorch, with particular attention to common pitfalls such as silent type conversions, in-place mutation, and probabilistic operations.\n",
    "\n",
    "This notebook is intended as an **introductory reference** for readers who are new to PyTorch tensors or who want to solidify their understanding before moving on to more advanced topics.\n",
    "\n",
    "It does **not** cover automatic differentiation (autograd), neural network modules, or optimisation routines, which will be addressed in subsequent notebooks in this tutorial series.\n",
    "\n",
    "**Recommended prerequisites:** Basic Python programming and familiarity with NumPy arrays.\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Angze Li\n",
    "\n",
    "**Last updated:** 2026-01-31 \n",
    "\n",
    "**Version:** v1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "af0dd6ae-360b-4a07-bda3-b18d23536333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in /opt/anaconda3/lib/python3.11/site-packages (2.10.0)\n",
      "Requirement already satisfied: filelock in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (3.1.3)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in /opt/anaconda3/lib/python3.11/site-packages (from torch) (2023.10.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/anaconda3/lib/python3.11/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/anaconda3/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ac605f0e-84e3-4c24-b99b-a38769e1fdd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c18e99-6bad-46c0-b7dd-9018fbe65fa3",
   "metadata": {},
   "source": [
    "# Initialising a tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68aadfa5-5a27-40c6-8c08-af4a8d9b12a4",
   "metadata": {},
   "source": [
    "## Directly from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4c649a7f-8859-4b2f-9a1e-9a487c7b020f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'torch.Tensor'>\n",
      "[[1, 2], [3, 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "data = [[1, 2],[3, 4]]\n",
    "x_data = torch.tensor(data)\n",
    "print(type(data), type(x_data))\n",
    "print(data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416d3f55-abda-44ae-bdfc-b12c69f57bd2",
   "metadata": {},
   "source": [
    "## From a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ec47bd26-55a4-4e98-b677-1ea2931beb1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ones Tensor: \n",
      " tensor([[1, 1],\n",
      "        [1, 1]]) \n",
      "\n",
      "Random Tensor: \n",
      " tensor([[0.7313, 0.7006],\n",
      "        [0.2860, 0.9104]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "x_ones = torch.ones_like(x_data) # retains the properties of x_data, but all entries has scalar value of 1.\n",
    "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
    "\n",
    "x_rand = torch.rand_like(x_data, dtype=torch.float) # retains the properties of x_data, but all entries are filled in with random numbers.\n",
    "print(f\"Random Tensor: \\n {x_rand} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "480a699c-4f05-4028-883d-c91489a6b8cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'torch.Tensor'>\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "np_array = np.array(data)\n",
    "x_np = torch.from_numpy(np_array)\n",
    "print(type(np_array), type(x_np))\n",
    "print(np_array)\n",
    "print(x_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cf8f2c3-f943-4815-ab71-9ef00e8fd177",
   "metadata": {},
   "source": [
    "## From another tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06e1ec91-a05d-43cd-b569-b5aff080ee60",
   "metadata": {},
   "source": [
    "## With random or constant values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "88b6d092-a85e-48eb-a95a-7144733fa0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Tensor: \n",
      " tensor([[0.6172, 0.8733, 0.0051],\n",
      "        [0.6939, 0.4970, 0.8543]]) \n",
      "\n",
      "Ones Tensor: \n",
      " tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]]) \n",
      "\n",
      "Zeros Tensor: \n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "shape = (2,3,)\n",
    "rand_tensor = torch.rand(shape)\n",
    "ones_tensor = torch.ones(shape)\n",
    "zeros_tensor = torch.zeros(shape)\n",
    "\n",
    "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
    "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
    "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee370d51-6490-402b-8e54-0a833a8e64b5",
   "metadata": {},
   "source": [
    "- `shape = (2,3)` and `shape = (2,3,)` produce exactly the same tensor. The trailing comma is optional for tuples with ≥2 elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff3d5726-73a5-4332-b6dc-c2f2bdabf463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shape1 = (2, 3)\n",
    "shape2 = (2, 3,)\n",
    "\n",
    "torch.rand(shape1).shape == torch.rand(shape2).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be2945c-d9b6-46c4-98fc-f290ff7b46b6",
   "metadata": {},
   "source": [
    "## 3D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ec5c3a4-3a69-4fa2-89c1-fc93478eee6a",
   "metadata": {},
   "source": [
    "We can start from **1D** tensor, which has the same shape as a vector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "022a578c-3456-42bc-9b36-b70caa94d005",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([1, 2, 3])\n",
    "x.shape == (3,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c93019-24ca-4490-a991-bd892e2951d8",
   "metadata": {},
   "source": [
    "2D tensor has the same shape as a table or matrix, with first number indicating the number of **rows** and second for number of **columns**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "854ce5a9-0827-4b4f-8e7b-61b2cb4d1b30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.tensor([\n",
    "    [1, 2, 3],\n",
    "    [4, 5, 6]\n",
    "])\n",
    "x.shape == (2, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1857d8b9-3f87-407c-9d60-7167ed584200",
   "metadata": {},
   "source": [
    "**3D tensor is a stack of matrices.**\n",
    "- The first number indicates the number of matrices\n",
    "- The second and third number indicate the row number and column number of each matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b0138d5b-2644-485a-9551-68fa410559b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.5022, 0.3114, 0.7381, 0.2250],\n",
      "         [0.6941, 0.9313, 0.1761, 0.4454],\n",
      "         [0.2353, 0.1207, 0.7735, 0.2856]],\n",
      "\n",
      "        [[0.6181, 0.9139, 0.7393, 0.8570],\n",
      "         [0.7942, 0.7370, 0.0470, 0.7061],\n",
      "         [0.6873, 0.8154, 0.5302, 0.4817]]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand((2, 3, 4))\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b62804d9-f331-4ad9-bdac-56d6d72a3011",
   "metadata": {},
   "source": [
    "Indexing makes it obvious. Each index *peels off* one dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0fd78634-0583-43d1-a5dc-9db8c50260b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 4])\n",
      "torch.Size([3, 4])\n",
      "torch.Size([4])\n",
      "tensor(0.5022)\n"
     ]
    }
   ],
   "source": [
    "print(x.shape)      \n",
    "print(x[0].shape)     \n",
    "print(x[0,0].shape)  \n",
    "print(x[0,0,0])     # scalar at [0,0,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e45ba1-d457-4292-add4-a948357ec856",
   "metadata": {},
   "source": [
    "# Attributes of a Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0b6fd4-5292-4949-bdcb-9e3f4fd1b27b",
   "metadata": {},
   "source": [
    "Tensor attributes describe their shape, datatype, and the device on which they are stored."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0c336f8-a632-4710-8cf9-8e154328b3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of tensor: torch.Size([3, 4])\n",
      "Datatype of tensor: torch.float32\n",
      "Device tensor is stored on: cpu\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.rand(3,4)\n",
    "\n",
    "print(f\"Shape of tensor: {tensor.shape}\")\n",
    "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
    "print(f\"Device tensor is stored on: {tensor.device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2353d802-7d47-4e8e-b1ee-5d813f2b343b",
   "metadata": {},
   "source": [
    "## float32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39484de5-5940-4fd4-96db-4a4a7aca5e77",
   "metadata": {},
   "source": [
    "`float32` can represent:\n",
    "- each number in the tensor is stored as a 32-bit floating-point number, aka **single precision**\n",
    "- ~7 decimal digits of precision\n",
    "- numbers up to ~10³⁸\n",
    "\n",
    "float32 is the **default** dtype for PyTorch tensors, since float32 is fast on CPUs and GPUs, and accurate enough for most ML tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47e3c8ad-14a5-4e9f-afec-5ec4392a8e63",
   "metadata": {},
   "source": [
    "## Device type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c7e03ae-0bd8-4494-952b-489a55635cb8",
   "metadata": {},
   "source": [
    "By default, PyTorch creates tensors on **cpu** because:\n",
    "- CPUs are always available\n",
    "- GPUs are optional\n",
    "- moving data to GPU has overhead\n",
    "\n",
    "We need to manually specify if we wish to create the tensor on GPU. For **MacBook**, PyTorch uses **MPS (Metal Performance Shaders)**. We can check if MPS works by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "af55e576-7383-4e71-bfa8-097bf491c969",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.backends.mps.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c595dd-baac-4d1a-bbac-3a402330e54e",
   "metadata": {},
   "source": [
    "And if it is `True`, we can transfer the tensor to GPU. But we almost always do not need for computation unless datasets get large or models are complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9d11ff63-ae59-4d1b-9042-1ffeb9b0c559",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")\n",
    "x = x.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1441f41-43b2-40cd-8d4f-cb01612b85ad",
   "metadata": {},
   "source": [
    "It is also for this reason that we should have this setup at the start of the program:\n",
    "```python\n",
    "import torch \n",
    "torch.set_default_dtype(torch.double)\n",
    "device = torch.device(\"cpu\")`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e64d788-ae9b-411d-8b05-7a8c4fc0bf11",
   "metadata": {},
   "source": [
    "For Nvidia GPUs, we can use `tensor = torch.rand(3, 4).to(\"cuda\")` or `tensor = torch.rand(3, 4, device=\"cuda\")`, which only if works when `torch.cuda.is_available() == True`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3350621-fbf2-4e44-9d6a-1bdfc14b08d6",
   "metadata": {},
   "source": [
    "# Operations on Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac50c8f3-dd17-4ccc-8bef-09a34833b2a2",
   "metadata": {},
   "source": [
    "## Standard NumPy-like indexing and slicing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6490e355-c513-48a4-9344-e8e74fe40968",
   "metadata": {},
   "source": [
    "- Either `:` or `...` can be used for slicing.\n",
    "- `tensor[:,1] = 0` can set the **whole column** with index 1 (second column) to be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "5cf99533-0236-4b77-8a1a-14f28c156558",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First row: tensor([1., 1., 1., 1.])\n",
      "First column: tensor([1., 1., 1., 1.])\n",
      "Last column: tensor([1., 1., 1., 1.])\n",
      "First row, first column: 1.0\n",
      "tensor([[1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.],\n",
      "        [1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.ones(4, 4)\n",
    "print(f\"First row: {tensor[0]}\")\n",
    "print(f\"First column: {tensor[:, 0]}\")\n",
    "print(f\"Last column: {tensor[..., -1]}\")\n",
    "print(f\"First row, first column: {tensor[0,0]}\")\n",
    "\n",
    "tensor[:,1] = 0\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27a92102-c8ba-48e6-8312-016eaa417c8e",
   "metadata": {},
   "source": [
    "## Joining tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ff4854-4074-4555-b774-2d756f6266b2",
   "metadata": {},
   "source": [
    "`torch.cat` can be used to concatenate a sequence of tensors along a given dimension.\n",
    "- Setting `dim=0` concatenates rows of the tensor.\n",
    "- Setting `dim=1` concatenates columns of the tensor.\n",
    "- If the tensor is 3D, setting `dim=2` concatenates \"features\" of the tensor.\n",
    "- `dim=-1` refers to the last dimension of the tensor, and so on for `dim=-2`, `dim=-3`, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c496ce5b-6919-4d0c-870d-a00866d71827",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that these tensors are 2D\n",
    "tensor1 = torch.ones(4, 4) \n",
    "tensor0 = torch.zeros(4, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1fbe17b8-1782-4291-8264-fba23b998a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.cat([tensor1, tensor0], dim=0)\n",
    "print(t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9efc700b-10ce-4512-98a8-15c91f6a5aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.],\n",
      "        [1., 1., 1., 1., 0., 0., 0., 0.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True],\n",
       "        [True, True, True, True, True, True, True, True]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = torch.cat([tensor1, tensor0], dim=1)\n",
    "print(t1)\n",
    "torch.cat([tensor1, tensor0], dim=1) == torch.cat([tensor1, tensor0], dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6365c10-8906-4262-9c03-47304e161baf",
   "metadata": {},
   "source": [
    "## Matrix arithmetic computations of 2D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3dda0ce-fd2c-4f5a-af4b-008984e34d28",
   "metadata": {},
   "source": [
    "-  ``tensor.T`` returns the **transpose** of a tensor.\n",
    "-  The **matrix multiplication** can be computed by `tensor1 @ tensor2`. \n",
    "-  Another way of matrix multiplication is by `tensor1.matmul(tensor2)`, which returns the same result as the `@` method.\n",
    "-  The third way of matrix multiplication is by `torch.matmul(tensor1, tensor2, out=tensor3)`. In this way, the result can be stored in a specified way, i.e., in `tensor3`.\n",
    "-  Matrix multiplication is only defined when the inner dimensions of `tensor1` and `tensor2` are compatible; otherwise, PyTorch raises a **runtime error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "f7dfd857-d58d-46b1-a87d-4da57615266d",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "])   # shape (2, 3)\n",
    "\n",
    "B = torch.tensor([\n",
    "    [7.,  8.],\n",
    "    [9., 10.],\n",
    "    [11., 12.]\n",
    "])   # shape (3, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "dd9be753-f721-4e78-827e-968d3cea30c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 58.,  64.],\n",
      "        [139., 154.]])\n",
      "tensor([[ 58.,  64.],\n",
      "        [139., 154.]])\n",
      "tensor([[ 58.,  64.],\n",
      "        [139., 154.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the matrix multiplication between two tensors. y1, y2, y3 will have the same value\n",
    "y1 = A @ B\n",
    "y2 = A.matmul(B)\n",
    "torch.matmul(A, B, out=y3)\n",
    "\n",
    "print(y1)\n",
    "print(y2)\n",
    "print(y3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b68caa-4c68-4ac9-90f5-5d9228e31fcb",
   "metadata": {},
   "source": [
    "## Element-wise arithmetic computations of 2D tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09c7f1b-d0f3-467f-8abe-a2d55474e5f5",
   "metadata": {},
   "source": [
    "-  The **element-wise product** multiplies corresponding entries of two tensors with the same shape.\n",
    "-  The element-wise product can be computed using the `*` operator, i.e. `tensor1 * tensor2`.\n",
    "-  Another way to compute the element-wise product is by `tensor1.mul(tensor2)`, which returns the same result as the `*` operator.\n",
    "-  A third way to compute the element-wise product is by `torch.mul(tensor1, tensor2, out=tensor3)`. In this way, the result is stored directly in `tensor3`.\n",
    "-  Element-wise multiplication requires `tensor1` and `tensor2` to have the **same shape** (or be broadcastable); otherwise, PyTorch raises a **runtime error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "de9e59c2-8b9c-4872-9acc-ac5978239fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "C = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "])   # shape (2, 3)\n",
    "\n",
    "D = torch.tensor([\n",
    "    [10., 20., 30.],\n",
    "    [40., 50., 60.]\n",
    "])   # shape (2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "d23320d8-8061-4118-b6ea-de05032b79e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 10.,  40.,  90.],\n",
      "        [160., 250., 360.]])\n",
      "tensor([[ 10.,  40.,  90.],\n",
      "        [160., 250., 360.]])\n",
      "tensor([[ 10.,  40.,  90.],\n",
      "        [160., 250., 360.]])\n"
     ]
    }
   ],
   "source": [
    "# This computes the element-wise product. z1, z2, z3 will have the same value\n",
    "z1 = C * D\n",
    "z2 = C.mul(D)\n",
    "torch.mul(C, D, out=z3)\n",
    "\n",
    "print(z1)\n",
    "print(z2)\n",
    "print(z3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e00a483b-80a3-4f62-9301-8e52602cbd99",
   "metadata": {},
   "source": [
    "## Aggregation and single-element tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a52e5-da51-4823-87f9-d268cbece673",
   "metadata": {},
   "source": [
    "- `tensor.sum()` computes the sum, i.e. aggregates of all elements in `tensor`.\n",
    "- The result of this opeartion is still a **0D tensor** (scalar tensor)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "17ac8982-2118-45ac-9939-03963e570c3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(910.) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "agg = z1.sum()\n",
    "print(agg, type(agg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72209c8d-b384-4fb8-ac57-a62dd5bdd338",
   "metadata": {},
   "source": [
    "- `agg` can be converted to a **numerical value** by `item()`:\n",
    "\n",
    "Compare the result of the cell below and the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f2f731a3-27c6-42d6-9b92-2ef3b59698fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910.0 <class 'float'>\n"
     ]
    }
   ],
   "source": [
    "agg_item = agg.item()\n",
    "print(agg_item, type(agg_item))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4288d827-d7a3-4bf1-a383-2b18d6ad36ad",
   "metadata": {},
   "source": [
    "## In-place operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce45b61-f8f7-42a2-ae0d-9027786ffe8f",
   "metadata": {},
   "source": [
    "Operations that store the result into the operand are called **in-place**.\n",
    "\n",
    "**Golden rule: Any PyTorch operation whose name ends with _ modifies the tensor in place.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10dbadd-57b3-4724-9605-00e76cb60f4b",
   "metadata": {},
   "source": [
    "### Arithmetic operations\n",
    "-  Common in-place **arithmetic operations** include `tensor.add_(x)`, `tensor.sub_(x)`, `tensor.mul_(x)`, and `tensor.div_(x)`.\n",
    "-  In-place operations can be **memory-efficient**, as they avoid allocating new tensors.\n",
    "-  In-place operations should be used with caution when **automatic differentiation** is involved, as modifying tensors that participate in the computation graph may raise a **runtime error**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "f4ad8bb7-ba77-4bd0-9563-c95696a2f9ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[10., 20., 30.],\n",
      "        [40., 50., 60.]])\n",
      "After add_(2):\n",
      " tensor([[12., 22., 32.],\n",
      "        [42., 52., 62.]])\n",
      "After sub_(1):\n",
      " tensor([[ 9., 19., 29.],\n",
      "        [39., 49., 59.]])\n",
      "After mul_(2):\n",
      " tensor([[ 20.,  40.,  60.],\n",
      "        [ 80., 100., 120.]])\n",
      "After div_(2):\n",
      " tensor([[ 5., 10., 15.],\n",
      "        [20., 25., 30.]])\n"
     ]
    }
   ],
   "source": [
    "D = torch.tensor([\n",
    "    [10., 20., 30.],\n",
    "    [40., 50., 60.]\n",
    "]) \n",
    "\n",
    "print(\"Original tensor:\\n\", D)\n",
    "\n",
    "E = D.clone()\n",
    "E.add_(2)\n",
    "print(\"After add_(2):\\n\", E)\n",
    "\n",
    "E = D.clone()\n",
    "E.sub_(1)\n",
    "print(\"After sub_(1):\\n\", E)\n",
    "\n",
    "E = D.clone()\n",
    "E.mul_(2)\n",
    "print(\"After mul_(2):\\n\", E)\n",
    "\n",
    "E = D.clone()\n",
    "E.div_(2)\n",
    "print(\"After div_(2):\\n\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f8669c5-c87f-4013-ad6d-050d9704a02b",
   "metadata": {},
   "source": [
    "### Filling and assignment operations\n",
    "-  Common in-place **tensor filling and assignment operations** include `tensor.copy_(other_tensor)`, `tensor.fill_(constant)`, and `tensor.zero_()`.\n",
    "-  `tensor.copy_(other_tensor)` copies the contents of `other_tensor` into `tensor`, making the two tensors have identical values.\n",
    "-  `tensor.fill_(constant)` sets all entries of `tensor` to the specified constant value.\n",
    "-  `tensor.zero_()` sets all entries of `tensor` to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "0451baac-24e4-4f55-bb81-52eb9780ca0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "After copy_(D):\n",
      " tensor([[10., 20., 30.],\n",
      "        [40., 50., 60.]])\n",
      "After fill_(10):\n",
      " tensor([[10., 10., 10.],\n",
      "        [10., 10., 10.]])\n",
      "After zero_():\n",
      " tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "C = torch.tensor([\n",
    "    [1., 2., 3.],\n",
    "    [4., 5., 6.]\n",
    "]) \n",
    "\n",
    "print(\"Original tensor:\\n\", C)\n",
    "\n",
    "F = C.clone()\n",
    "F.copy_(D)\n",
    "print(\"After copy_(D):\\n\", F)\n",
    "\n",
    "F = C.clone()\n",
    "F.fill_(10)\n",
    "print(\"After fill_(10):\\n\", F)\n",
    "\n",
    "F = C.clone()\n",
    "F.zero_()\n",
    "print(\"After zero_():\\n\", F)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83afad32-3532-49c6-aef3-2bbd79c39005",
   "metadata": {},
   "source": [
    "###  Element-wise activation and transformation operations\n",
    "- In-place **element-wise activation and transformation operations** replace the entries of a tensor by applying nonlinear activation functions or value transformations.\n",
    "-  Common in-place **element-wise activation and transformation operations** include `tensor.relu_()`, `tensor.sigmoid_()`, `tensor.clamp_(min, max)`, and `tensor.abs_()`.\n",
    "-  `tensor.relu_()` applies the **Rectified Linear Unit (ReLU) function** to each entry of `tensor` in place, setting all negative values to zero.\n",
    "-  `tensor.sigmoid_()` applies the **sigmoid function** to each entry of `tensor` in place, mapping all values to the interval `(0, 1)`.\n",
    "-  `tensor.clamp_(min, max)` restricts all entries of `tensor` to lie within the specified interval `[min, max]`.\n",
    "-  `tensor.abs_()` replaces each entry of `tensor` with its **absolute value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "f74b88ce-0d2f-423a-a311-cb632271a3ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[-2.0000, -0.5000,  0.0000],\n",
      "        [ 0.5000,  1.0000,  2.0000]])\n",
      "After relu_():\n",
      " tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 1.0000, 2.0000]])\n",
      "After sigmoid_():\n",
      " tensor([[0.1192, 0.3775, 0.5000],\n",
      "        [0.6225, 0.7311, 0.8808]])\n",
      "After clamp_():\n",
      " tensor([[0.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 1.0000, 1.0000]])\n",
      "After abs_():\n",
      " tensor([[2.0000, 0.5000, 0.0000],\n",
      "        [0.5000, 1.0000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([\n",
    "    [-2.0, -0.5,  0.0],\n",
    "    [ 0.5,  1.0,  2.0]\n",
    "])\n",
    "\n",
    "print(\"Original tensor:\\n\", tensor)\n",
    "\n",
    "E = tensor.clone()\n",
    "E.relu_()\n",
    "print(\"After relu_():\\n\", E)\n",
    "\n",
    "E = tensor.clone()\n",
    "E.sigmoid_()\n",
    "print(\"After sigmoid_():\\n\", E)\n",
    "\n",
    "E = tensor.clone()\n",
    "E.clamp_(min=0, max=1)\n",
    "print(\"After clamp_():\\n\", E)\n",
    "\n",
    "E = tensor.clone()\n",
    "E.abs_()\n",
    "print(\"After abs_():\\n\", E)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2c9465-0a7b-4e97-af4f-5d1565d8cdb9",
   "metadata": {},
   "source": [
    "## In-place random value generation operations\n",
    "\n",
    "-  In-place **random value generation operations** replace the entries of a tensor with randomly generated values.\n",
    "-  `tensor.normal_()` fills `tensor` with values drawn from a **normal (Gaussian) distribution** with mean 0 and standard deviation 1.\n",
    "-  `tensor.uniform_()` fills `tensor` with values drawn from a **uniform distribution** on the interval `[0, 1)`.\n",
    "-  `tensor.bernoulli_(p)` fills `tensor` with values drawn from a **Bernoulli distribution**, where each entry takes the value 1 with probability `p` and 0 with probability `1 - p`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a70aada5-1344-4ad7-bc90-26d88b99095a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor:\n",
      " tensor([[-2.0000, -0.5000,  0.0000],\n",
      "        [ 0.5000,  1.0000,  2.0000]])\n",
      "After normal_():\n",
      " tensor([[-0.1153, -1.1834, -0.5861],\n",
      "        [-1.2766,  0.8045, -0.1688]])\n",
      "After uniform_():\n",
      " tensor([[0.0560, 0.1999, 0.4096],\n",
      "        [0.0254, 0.5228, 0.8127]])\n",
      "After bernoulli_(0.3):\n",
      " tensor([[0., 0., 1.],\n",
      "        [0., 0., 0.]])\n",
      "After bernoulli_(0.7):\n",
      " tensor([[0., 0., 1.],\n",
      "        [1., 0., 1.]])\n"
     ]
    }
   ],
   "source": [
    "tensor = torch.tensor([\n",
    "    [-2.0, -0.5,  0.0],\n",
    "    [ 0.5,  1.0,  2.0]\n",
    "])\n",
    "\n",
    "print(\"Original tensor:\\n\", tensor)\n",
    "\n",
    "G = tensor.clone()\n",
    "G.normal_()\n",
    "print(\"After normal_():\\n\", G)\n",
    "\n",
    "G = tensor.clone()\n",
    "G.uniform_()\n",
    "print(\"After uniform_():\\n\", G)\n",
    "\n",
    "G = tensor.clone()\n",
    "G.bernoulli_(0.3)\n",
    "print(\"After bernoulli_(0.3):\\n\", G)\n",
    "\n",
    "G = tensor.clone()\n",
    "G.bernoulli_(0.7)\n",
    "print(\"After bernoulli_(0.7):\\n\", G)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2d88d2-dbca-4a2c-ad1c-3723a46131a3",
   "metadata": {},
   "source": [
    "# Bridging PyTorch with NumPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94af21f-eaac-4080-b28e-922d31657bdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a9cce03f-a4a5-413e-945a-a243c8755fa8",
   "metadata": {},
   "source": [
    "## Tensor to NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4413ee6f-48b5-4142-a0ac-2b36a035cdf8",
   "metadata": {},
   "source": [
    "Tensors on the CPU and NumPy arrays can share their underlying memory locations, and **changing one will change the other**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "159abc56-3668-43a3-bb91-35818b012c9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "n: [[1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "t = torch.ones(2,3)\n",
    "print(f\"t: {t}\")\n",
    "n = t.numpy()\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3671a79e-1f03-4bbd-9c3a-804bd0bb98c9",
   "metadata": {},
   "source": [
    "A change in the tensor reflects in the NumPy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "3db76371-0fa0-4de1-9e1b-2e0aaa97f65d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "t: tensor([[11., 11., 11.],\n",
      "        [11., 11., 11.]])\n",
      "n: [[11. 11. 11.]\n",
      " [11. 11. 11.]]\n"
     ]
    }
   ],
   "source": [
    "t.add_(10)\n",
    "print(f\"t: {t}\")\n",
    "print(f\"n: {n}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a38a95-adaa-411a-a6c0-46dc0c6b88e4",
   "metadata": {},
   "source": [
    "## NumPy array to Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd35d0f4-9e2e-48b0-9f0d-05d32b9cae1f",
   "metadata": {},
   "source": [
    "-  Tensors with the **same shape and dimensionality** as the original NumPy array can be created using `torch.from_numpy()`.\n",
    "- Note that `dtype=torch.float64`. This is beacause NumPy creates float64 arrays by default, and `torch.from_numpy()` **preserves** the NumPy dtype exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "021cbdfc-f115-4804-9c55-77eb98f08fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [1. 1. 1. 1. 1.]\n",
      "t: tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.ones(5)\n",
    "print(f\"n: {n}\")\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"t: {t}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "bef70230-24de-4443-b3fb-ffb5a8463c65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "t: tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n = np.array([\n",
    "    [1.0, 2.0, 3.0],\n",
    "    [4.0, 5.0, 6.0]\n",
    "])\n",
    "print(f\"n: {n}\")\n",
    "t = torch.from_numpy(n)\n",
    "print(f\"t: {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3cda5dc-51a5-4233-910c-235bba9fd32f",
   "metadata": {},
   "source": [
    "Changes in the NumPy array also reflects in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "1d568d1d-61ed-49a2-9fe9-27a6a020b7d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n: [[11. 12. 13.]\n",
      " [14. 15. 16.]]\n",
      "t: tensor([[11., 12., 13.],\n",
      "        [14., 15., 16.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "n += 10\n",
    "print(f\"n: {n}\")\n",
    "print(f\"t: {t}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
