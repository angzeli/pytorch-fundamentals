# PyTorch Fundamentals

This repository contains a growing set of notes and notebooks exploring core PyTorch concepts.  
It currently starts with an introductory notebook on **PyTorch tensor fundamentals** ğŸ“.

The emphasis is on building **clear intuition** and **good habits** when working with PyTorch, rather than providing a comprehensive API reference.

---

## ğŸ“š Current Contents

### 1. PyTorch Tensor Fundamentals
- Tensor creation (from Python and NumPy)
- Shapes and dimensionality
- Data types (`dtype`) and device placement
- Arithmetic and element-wise operations
- In-place operations and common pitfalls 
- Random value generation and probabilistic operations 

Additional notebooks may be added over time as the repository grows ğŸŒ±.

---

## ğŸ¯ Scope and Intent

These materials are written as **learning and teaching notes**, intended to clarify how PyTorch tensors behave in practice.

Topics such as automatic differentiation (autograd), neural network modules, and optimisation routines are **not covered in the current notebook**, but may be introduced in future notebooks.

---

## ğŸ§© Recommended Prerequisites

- Basic Python programming
- Familiarity with NumPy arrays

---

## â–¶ï¸ How to Use

Each notebook is self-contained and can be read independently.  
Examples are designed to be minimal, explicit, and easy to experiment with.

---

## âœï¸ Author

**Angze Li**

---

## âš–ï¸ License

This project is licensed under the **MIT License**.
